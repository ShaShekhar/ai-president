LOG_FILE_PATH: /tmp/app.log
models:
  faster_whisper:
    model_size_or_path: small.en # medium.en, large-v1 etc
    device: cuda # cpu
    compute_type: float16 # for cpu: float32
    download_root: weights
  language_model:
    active_model: api # or local
    local:
      model_name: phi3
      model_class: Phi3_mini_128k_instruct
      download_dir: weights
      device: cuda
      # compute_type: auto
    api:
      # set the api key in .env file
      provider: gemini # default provider
      gemini:
        model_name: gemini-pro
      openai:
        model_name: GPT-4
  coqui:
    gpu: True
    model_path: weights/coqui/model.pth
    config_path: weights/coqui/config.json
    audio_clip: tests/clips/biden_clip.wav # audio to clone
    language: en
    speed: 1.30
  video_retalking:
    device: cuda
    base_dir: weights/checkpoints/
    video_clip: tests/clips/biden_clip.mp4 # video to clone

web_frontend:
  recording_time: 8 # in seconds
